{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8291e6-4a67-4fb0-b728-96a8b7a9c60e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Showcase Bark, a transformer-based text-to-audio model.\n",
    "\n",
    "https://github.com/suno-ai/bark\n",
    "\"\"\"\n",
    "import datetime as dt\n",
    "from time import perf_counter\n",
    "from typing import Tuple\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "from bark import SAMPLE_RATE, semantic_to_waveform, preload_models\n",
    "from bark.generation import generate_text_semantic\n",
    "from IPython.display import Audio\n",
    "from scipy.io.wavfile import write as write_wav\n",
    "\n",
    "# download and load all models\n",
    "preload_models()\n",
    "\n",
    "print(f\"{SAMPLE_RATE=}\")  # 24000\n",
    "\n",
    "def generate_sentence(text: str, history_prompt = None) -> Tuple[dict, np.array]:\n",
    "    \"\"\"\n",
    "    Short text to speech that returns a tuple of history_prompt [0] and audio array [1].\n",
    "    \"\"\"\n",
    "    semantic_tokens = generate_text_semantic(\n",
    "        text=text,\n",
    "        history_prompt=history_prompt,\n",
    "        temp=0.7,  # 0.7 is default; generation temperature (1.0 more diverse, 0.0 more conservative)\n",
    "        top_k=None,\n",
    "        top_p=None,\n",
    "        silent=False,  # disable progress bar\n",
    "        min_eos_p=0.05,  # this controls how likely the generation is to end or to hallucinate; default 0.2\n",
    "        max_gen_duration_s=None,\n",
    "        allow_early_stop=True,\n",
    "        use_kv_caching=True,  # default: False, text_to_semantic() uses True\n",
    "    )\n",
    "    out = semantic_to_waveform(\n",
    "        semantic_tokens,\n",
    "        history_prompt=history_prompt,\n",
    "        temp=0.999,  # 0.7 is default; generation temperature (1.0 more diverse, 0.0 more conservative)\n",
    "        silent=False,  # disable progress bar\n",
    "        output_full=True,  # True: return full generation [0] and adio array [1]; False: return only audio array\n",
    "    )\n",
    "    full_generation, audio = out\n",
    "    return full_generation, audio\n",
    "\n",
    "\n",
    "def gen_short_audio(text: str, speaker = None) -> np.array:\n",
    "    \"\"\"Short audio, allegedly works best up to 13 seconds.\"\"\"\n",
    "    _, audio = generate_sentence(text=text, history_prompt=speaker)\n",
    "    return audio\n",
    "\n",
    "\n",
    "def gen_long_audio(text: str, speaker = None) -> np.array:\n",
    "    \"\"\"Long audio, broken down by sentences aka tokens.\"\"\"\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    silence = np.zeros(int(0.25 * SAMPLE_RATE))  # quarter second of silence\n",
    "\n",
    "    audio_parts = []\n",
    "    for sentence in sentences:\n",
    "        full_generation, audio_part = generate_sentence(text=sentence, history_prompt=speaker)\n",
    "        audio_parts += [audio_part, silence.copy()]\n",
    "    \n",
    "    audio = np.concatenate(audio_parts)\n",
    "    return audio\n",
    "\n",
    "\n",
    "speaker = None  # random speaker\n",
    "# speaker = \"v2/en_speaker_9\"\n",
    "# speaker = \"v2/en_speaker_6\"  # suo favorite male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82f5328-7a31-4753-8d40-d31239c671af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get a rando sentence in order to determine if you like the speaker\n",
    "# Best use a sentence of the long text you want to render, because, \n",
    "# apparently, bark chooses random speakers according to the text's content.\n",
    "# text = \"\"\"\n",
    "#     Hello, my name is Suno. And, uh â€” and I like pizza. [laughs]\n",
    "#     But I also have other interests such as playing tic tac toe.\n",
    "# \"\"\"\n",
    "# text = \"Wubbalubbadubdub\"\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "start = perf_counter()\n",
    "full_generation, audio = generate_sentence(text)\n",
    "duration_s = perf_counter() - start\n",
    "print(f\"Done. Took {round(duration_s)} seconds\")\n",
    "Audio(audio, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d3fa8b-1d9c-4fb2-b73a-22cd65717fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optionally, load a speaker from disk\n",
    "full_generation = dict(np.load(\"alicia.npz\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5b8794-19ff-4531-9013-758337953526",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate audio from text\n",
    "# when you have a speaker you are happy with, you may want to use this speaker for long text generation\n",
    "\n",
    "text = \"\"\"\n",
    "    Wubbalubbadubdub.\n",
    "\"\"\"\n",
    "\n",
    "start = perf_counter()\n",
    "audio = gen_long_audio(text, speaker=full_generation)\n",
    "duration_s = perf_counter() - start\n",
    "print(f\"Done. Took {round(duration_s)} seconds\")\n",
    "Audio(audio, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1899a977-69d0-44ce-a681-233098b8a23e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In case you found a speaker you like, write the full_generation to disk for later use\n",
    "from pathlib import Path\n",
    "\n",
    "filename=\"alicia.npz\"\n",
    "\n",
    "if Path(filename).exists():\n",
    "    print(\"Meh. Won't save.\")\n",
    "else:\n",
    "    np.savez(filename, **full_generation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
